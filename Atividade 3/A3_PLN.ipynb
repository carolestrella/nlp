{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3_PLN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Criar tabela top 10 (lista com 10 posições)\n",
        "Ranking de similaridade\n",
        "\n",
        "Bow binário X tf-idf\n",
        "\n",
        "Vou ter uma query contendo um texto e uma categoria. Depois de montar ranking de similaridade, se for da mesma categoria, incrementa no vetor top10."
      ],
      "metadata": {
        "id": "04qIxCf628JT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aluna: Carolina Estrella\n",
        "\n",
        "**Matrícula: 180074792**"
      ],
      "metadata": {
        "id": "OEqjSxqGArj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "import math\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "6IqBqLdB6HZS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWYWuWcU7yzJ",
        "outputId": "7fe30651-3b5a-4625-9bb9-867c600cdaba"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-Processing"
      ],
      "metadata": {
        "id": "h_0toeoX7XuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processing(text):\n",
        "  stopwords_nltk = stopwords.words('english')\n",
        "  stemmer = PorterStemmer()\n",
        "  wn_lemmas = set(wn.all_lemma_names())\n",
        "  \n",
        "  words = re.sub(r'[\\s!%*~\\^´`=+<\\[\\]?&$:;@#.0-9()\\/\\\"\\'_-]+|[\\s]*[\\\\]u[a-z0-9]{4}[\\s]*|[\\s]*http[^\\s]+[\\s]*', \" \", text.lower())\n",
        "  words = re.sub(r'\\brt\\b', \"\", words)\n",
        "  words = re.sub(r'[\\\\]+', \" \", words)\n",
        "  words = words.strip()\n",
        "  \n",
        "  phrase = \"\"\n",
        "  words = words.split()\n",
        "\n",
        "  for x in words:\n",
        "    if x not in stopwords_nltk and x in wn_lemmas:\n",
        "      x = stemmer.stem(x)\n",
        "      phrase = phrase + \" \" + x\n",
        "        \n",
        "  return phrase.strip()"
      ],
      "metadata": {
        "id": "T_OJJK1J7XIl"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = []\n",
        "corpus = []\n",
        "fileids = reuters.fileids()\n",
        "\n",
        "for file in fileids:\n",
        "  categories.append(reuters.categories(file))\n",
        "  corpus.append(pre_processing(reuters.raw(file)))\n",
        "\n",
        "df = pd.DataFrame({'ids':fileids, 'categories':categories, 'text':corpus})"
      ],
      "metadata": {
        "id": "IP-zw1tg6Mx5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "av8rvM9e7qKJ",
        "outputId": "a4e26ae1-4d06-4757-cb1a-095651083631"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 ids                                      categories  \\\n",
              "0         test/14826                                         [trade]   \n",
              "1         test/14828                                         [grain]   \n",
              "2         test/14829                                [crude, nat-gas]   \n",
              "3         test/14832  [corn, grain, rice, rubber, sugar, tin, trade]   \n",
              "4         test/14833                             [palm-oil, veg-oil]   \n",
              "...              ...                                             ...   \n",
              "10783   training/999                            [interest, money-fx]   \n",
              "10784  training/9992                                          [earn]   \n",
              "10785  training/9993                                          [earn]   \n",
              "10786  training/9994                                          [earn]   \n",
              "10787  training/9995                                          [earn]   \n",
              "\n",
              "                                                    text  \n",
              "0      asian fear damag u japan rift mount trade fric...  \n",
              "1      china daili vermin eat pct grain stock survey ...  \n",
              "2      japan revis long term energi demand downward m...  \n",
              "3      thai trade deficit first quarter thailand trad...  \n",
              "4      indonesia price rise sharpli indonesia crude p...  \n",
              "...                                                  ...  \n",
              "10783  u k money market shortag forecast revis bank e...  \n",
              "10784  knight inc quarterli prior pay april record ap...  \n",
              "10785   inc quarterli prior pay april record april seven  \n",
              "10786  nationwid cellular servic inc th loss six loss...  \n",
              "10787                       h automot year net dilut net  \n",
              "\n",
              "[10788 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7aa0a836-3e59-43e1-aba9-0c25836496ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ids</th>\n",
              "      <th>categories</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test/14826</td>\n",
              "      <td>[trade]</td>\n",
              "      <td>asian fear damag u japan rift mount trade fric...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test/14828</td>\n",
              "      <td>[grain]</td>\n",
              "      <td>china daili vermin eat pct grain stock survey ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test/14829</td>\n",
              "      <td>[crude, nat-gas]</td>\n",
              "      <td>japan revis long term energi demand downward m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test/14832</td>\n",
              "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
              "      <td>thai trade deficit first quarter thailand trad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test/14833</td>\n",
              "      <td>[palm-oil, veg-oil]</td>\n",
              "      <td>indonesia price rise sharpli indonesia crude p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10783</th>\n",
              "      <td>training/999</td>\n",
              "      <td>[interest, money-fx]</td>\n",
              "      <td>u k money market shortag forecast revis bank e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10784</th>\n",
              "      <td>training/9992</td>\n",
              "      <td>[earn]</td>\n",
              "      <td>knight inc quarterli prior pay april record ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10785</th>\n",
              "      <td>training/9993</td>\n",
              "      <td>[earn]</td>\n",
              "      <td>inc quarterli prior pay april record april seven</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10786</th>\n",
              "      <td>training/9994</td>\n",
              "      <td>[earn]</td>\n",
              "      <td>nationwid cellular servic inc th loss six loss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10787</th>\n",
              "      <td>training/9995</td>\n",
              "      <td>[earn]</td>\n",
              "      <td>h automot year net dilut net</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10788 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7aa0a836-3e59-43e1-aba9-0c25836496ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7aa0a836-3e59-43e1-aba9-0c25836496ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7aa0a836-3e59-43e1-aba9-0c25836496ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = \" \".join(corpus)\n",
        "tokens = phrase.split()\n",
        "vocab = sorted(set(tokens))"
      ],
      "metadata": {
        "id": "hcja43AV-RTP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bag of Words Binário"
      ],
      "metadata": {
        "id": "EoDRsuYYwNzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_binario = {}\n",
        "\n",
        "for i,doc in enumerate(corpus):\n",
        "  bow_binario[i] = dict()\n",
        "  for word in doc.split():\n",
        "    bow_binario[i][word] = 1"
      ],
      "metadata": {
        "id": "xcPJFAngwHzl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_binario"
      ],
      "metadata": {
        "id": "fHYA21YuwboB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bag of Words Ponderado"
      ],
      "metadata": {
        "id": "a4JE5tzMwj4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_ponderado = {}\n",
        "N = {} # quantidade de termos em cada documento\n",
        "\n",
        "for i,doc in enumerate(corpus):\n",
        "    bow_ponderado[i] = dict()\n",
        "    N[i] = len(doc.split())\n",
        "    for word in doc.split():\n",
        "        if word in bow_ponderado[i]:\n",
        "            bow_ponderado[i][word] += 1\n",
        "        else:\n",
        "            bow_ponderado[i][word] = 1\n",
        "\n",
        "for doc in bow_ponderado:\n",
        "    for word in bow_ponderado[doc]:\n",
        "        bow_ponderado[doc][word] /= N[doc]"
      ],
      "metadata": {
        "id": "olftRFdZ9s3h"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_ponderado"
      ],
      "metadata": {
        "id": "_Xrpwomg_WjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bag of Words Contagem"
      ],
      "metadata": {
        "id": "GXBiKlpBw8To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_contagem = {}\n",
        "\n",
        "for i,doc in enumerate(corpus):\n",
        "    bow_contagem[i] = dict()\n",
        "    for word in doc.split():\n",
        "        if word in bow_contagem[i]:\n",
        "            bow_contagem[i][word] += 1\n",
        "        else:\n",
        "            bow_contagem[i][word] = 1"
      ],
      "metadata": {
        "id": "jbmVCEPsA_pB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow_contagem"
      ],
      "metadata": {
        "id": "Hq6ICuq_xPLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inverse Document Frequency"
      ],
      "metadata": {
        "id": "xOwz-lThxzz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idf = {}\n",
        "for word in vocab:\n",
        "  idf[word] = 0\n",
        "  #contabilizar em quantos documentos a palavra word aparece\n",
        "  for doc in bow_contagem:\n",
        "    if word in bow_contagem[doc]:\n",
        "      idf[word] += 1\n",
        "\n",
        "for word in idf:\n",
        "  if(idf[word] == 0): continue\n",
        "  idf[word] = math.log(len(corpus)/idf[word])"
      ],
      "metadata": {
        "id": "dpGRO4azA0eS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf"
      ],
      "metadata": {
        "id": "_N8ECHKYySu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bag of Words TFIDF"
      ],
      "metadata": {
        "id": "rldWJS8A_If3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_tfidf = {}\n",
        "\n",
        "for doc in bow_ponderado:\n",
        "  bow_tfidf[doc] = dict()\n",
        "  for word in bow_ponderado[doc]:\n",
        "    bow_tfidf[doc][word] = bow_ponderado[doc][word]*idf[word]"
      ],
      "metadata": {
        "id": "9ufumjFY_hzR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = pd.DataFrame().from_records(bow_tfidf).fillna(0).T"
      ],
      "metadata": {
        "id": "COLrHFEJ_mwF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf"
      ],
      "metadata": {
        "id": "lXkJlnnf_0Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cosine Similarity"
      ],
      "metadata": {
        "id": "-FOV4Fgt_7JE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_dissimilarity(vector1, vector2):\n",
        "  prod_interno = 0\n",
        "\n",
        "  for i, value in enumerate(vector1):\n",
        "    prod_interno += value*vector2[i]\n",
        "\n",
        "  norma_vector1 = 0\n",
        "\n",
        "  for x in vector1:\n",
        "    norma_vector1 += x*x\n",
        "  \n",
        "  norma_vector1 = norma_vector1**0.5\n",
        "\n",
        "  #norma_vector1 = math.sqrt(sum([x**2 for x in vector1]))\n",
        "\n",
        "  norma_vector2 = 0\n",
        "\n",
        "  for x in vector1:\n",
        "    norma_vector2 += x*x\n",
        "  \n",
        "  norma_vector2 = norma_vector2**0.5\n",
        "\n",
        "  return prod_interno/(norma_vector1*norma_vector2)"
      ],
      "metadata": {
        "id": "zwvMUK-2AGYG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Recuperação de textos"
      ],
      "metadata": {
        "id": "LIutbJJ8AYA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top10 = [0] * 10\n",
        "\n",
        "category = categories[:100]\n",
        "\n",
        "for i in range(len(category)):\n",
        "  vector1 = tfidf.iloc[i]\n",
        "  results = []\n",
        "\n",
        "  for j in range(len(category)):\n",
        "    if(i == j): continue\n",
        "    vector2 = tfidf.iloc[j]\n",
        "    similarity = cosine_dissimilarity(vector1, vector2)\n",
        "    results.append((similarity,j))\n",
        "\n",
        "  results.sort(reverse=True)\n",
        "  best10 = results[:10]\n",
        "  for x, [sim,j] in enumerate(best10):\n",
        "    for c in category[j]:\n",
        "      if(c in category[i]): top10[x] += 1\n",
        "\n",
        "\n",
        "print(top10)"
      ],
      "metadata": {
        "id": "o3LQzrFl42Hz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b4eaec-85ce-4494-a56f-a96dbbb8bb7e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[78, 73, 60, 54, 53, 45, 49, 49, 45, 35]\n"
          ]
        }
      ]
    }
  ]
}