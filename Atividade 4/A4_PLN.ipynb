{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aula19/7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagation"
      ],
      "metadata": {
        "id": "mIdPHtdKogup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "7pe2J5u3rC2X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def factivation(x, tipo,t=0):\n",
        "  if tipo == 'degrau':\n",
        "    if x >= t:\n",
        "      y = 1\n",
        "    else:\n",
        "      y = 0\n",
        "  elif tipo == 'sigmoide':\n",
        "    y = 1/(1+math.exp(-x))\n",
        "  elif tipo == 'sinal':\n",
        "    if x >= 0:\n",
        "      y = 1\n",
        "    else:\n",
        "      y = -1\n",
        "  else:\n",
        "    y = 'ERRO: opcao invalida'\n",
        "  \n",
        "  return y"
      ],
      "metadata": {
        "id": "UIZU3FxNq_E5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_and = [[0,0],[0,1],[1,0],[1,1]]\n",
        "labels = [0,1,1,0]\n",
        "\n",
        "l = np.array(labels)\n",
        "X = np.array(data_and)"
      ],
      "metadata": {
        "id": "hoqun5tvs60h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xn2Ap5gtiPFs"
      },
      "outputs": [],
      "source": [
        "layer1 = np.array([np.random.random(2), np.random.random(2)])\n",
        "layer2 = np.array(np.random.random(2))\n",
        "\n",
        "O = []\n",
        "F = []\n",
        "\n",
        "for i,x in enumerate(X):\n",
        "  layer1_o = []\n",
        "  layer_f = 0 \n",
        "  for neuron in range(0,len(layer1)):\n",
        "    m = np.multiply(x, layer1[neuron])\n",
        "    u = np.sum(m)\n",
        "    layer1_o.append(factivation(u, 'sigmoide'))\n",
        "   \n",
        "  m = np.multiply(layer1_o, layer2)\n",
        "  u = np.sum(m)\n",
        "  layer_f = factivation(u, 'sigmoide')\n",
        "\n",
        "\n",
        "  O.append(layer1_o)\n",
        "  F.append(layer_f)\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#backwards"
      ],
      "metadata": {
        "id": "LcUsYoU6zmVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0.1\n",
        "grad_layer2 = []\n",
        "grad_layer1 = []\n",
        "\n",
        "for i,x in enumerate(X):\n",
        "  grad3 = (F[i]-labels[i]) * (F[i]*(1-F[i]))\n",
        "  grad2 = (O[i][1]*(1-O[i][1])) * grad3 * layer2[1]\n",
        "  grad1 = (O[i][0]*(1-O[i][0])) * grad3 * layer2[0]\n",
        "\n",
        "  for j, weight in enumerate(layer2):\n",
        "    layer2[j] = l * grad3 * weight\n",
        "  \n",
        "  for j, weight in enumerate(layer1):\n",
        "    layer1[j][1] = l * grad2 * weight[1]\n",
        "    layer1[j][0] = l * grad1 * weight[0]\n",
        "\n",
        "  print(f\"Gradient 1: {grad1}\")\n",
        "  print(f\"Gradient 2: {grad2}\")\n",
        "  print(f\"Gradient 3: {grad3}\")\n",
        "  print(\"\\n\")\n",
        "  print(f\"Layer 1 Weights: {layer1}\")\n",
        "  print(f\"Layer 2 Weights: {layer2}\")\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pu5NTbxzn_Z",
        "outputId": "a4cdeb94-5fe1-4925-8d46-eb3bd635713f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient 1: 4.933802464833819e-43\n",
            "Gradient 2: 5.368598110376115e-43\n",
            "Gradient 3: 0.13596439461829804\n",
            "\n",
            "\n",
            "Layer 1 Weights: [[-0. -0.]\n",
            " [-0. -0.]]\n",
            "Layer 2 Weights: [1.97352099e-43 2.14743924e-43]\n",
            "---------------------\n",
            "Gradient 1: -4.970731808428097e-45\n",
            "Gradient 2: -5.852382428726357e-45\n",
            "Gradient 3: -0.10930486865209778\n",
            "\n",
            "\n",
            "Layer 1 Weights: [[0. 0.]\n",
            " [0. 0.]]\n",
            "Layer 2 Weights: [-2.15715452e-45 -2.34725565e-45]\n",
            "---------------------\n",
            "Gradient 1: 5.582576628038381e-47\n",
            "Gradient 2: 5.91390986571183e-47\n",
            "Gradient 3: -0.10821148631683376\n",
            "\n",
            "\n",
            "Layer 1 Weights: [[0. 0.]\n",
            " [0. 0.]]\n",
            "Layer 2 Weights: [2.33428897e-47 2.54000022e-47]\n",
            "---------------------\n",
            "Gradient 1: 6.401690075775475e-49\n",
            "Gradient 2: 7.999212067657639e-49\n",
            "Gradient 3: 0.13933359670988207\n",
            "\n",
            "\n",
            "Layer 1 Weights: [[0. 0.]\n",
            " [0. 0.]]\n",
            "Layer 2 Weights: [3.25244878e-49 3.53907366e-49]\n",
            "---------------------\n"
          ]
        }
      ]
    }
  ]
}